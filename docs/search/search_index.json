{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"IMLS WIFISESS This is documentation for the WIFISESS data collection pilot. Overview","title":"Home"},{"location":"#imls-wifisess","text":"This is documentation for the WIFISESS data collection pilot. Overview","title":"IMLS WIFISESS"},{"location":"overview/","text":"Overview The WIFISESS data collection pilot has many moving pieces. It involves: Hardware : For the pilot, a participating library must have a Raspberry Pi and one of a (currently limited) number of USB wifi adapters. API Key : Participation requires an API key from api.data.gov , and that key must be approved within the api.data.gov administrative interface. Configuration : The Raspberry Pi must be set up and configured in a particular way. A bash script is used to bootstrap an ansible playbook that downloads the required software, asks the librarian for three pieces of information (API key, FCFS Seq Id, and a tag to identify the Pi), and locks down the device so it cannot be accessed again . Several pieces of custom software were developed to support the configuration of the Pi. Software : On the Pi, we run session-counter , an application we developed to monitor wifi usage and maintain anonymity while reporting back to the data collection backend. It monitors, filters, and then reports data via HTTPS POST to ReVal, a data validator capable of handling a wide variety of inputs. Server Stack : Our server stack involves using the api.data.gov API manager. (This is actually an instance of api-umbrella , an open source tool for managing APIs and keys and throttling requests.) We pass data from api.data.gov to ReVal , a validation library developed by 18F and in use with several federal agencies. If the data validates, we then pass it to Directus , an open source headless CMS; this saved us developing an API for our Postgres instance, as it can automatically inspect a table and present an HTTPS POST API for CRUD operations on those tables. The entire stack is managed as a CloudFoundry buildpack running on cloud.gov . Everything used in the pilot is free and open source software. This site documents each of these pieces: how to maintain, build, test, and deploy the components involved.","title":"Overview"},{"location":"overview/#overview","text":"The WIFISESS data collection pilot has many moving pieces. It involves: Hardware : For the pilot, a participating library must have a Raspberry Pi and one of a (currently limited) number of USB wifi adapters. API Key : Participation requires an API key from api.data.gov , and that key must be approved within the api.data.gov administrative interface. Configuration : The Raspberry Pi must be set up and configured in a particular way. A bash script is used to bootstrap an ansible playbook that downloads the required software, asks the librarian for three pieces of information (API key, FCFS Seq Id, and a tag to identify the Pi), and locks down the device so it cannot be accessed again . Several pieces of custom software were developed to support the configuration of the Pi. Software : On the Pi, we run session-counter , an application we developed to monitor wifi usage and maintain anonymity while reporting back to the data collection backend. It monitors, filters, and then reports data via HTTPS POST to ReVal, a data validator capable of handling a wide variety of inputs. Server Stack : Our server stack involves using the api.data.gov API manager. (This is actually an instance of api-umbrella , an open source tool for managing APIs and keys and throttling requests.) We pass data from api.data.gov to ReVal , a validation library developed by 18F and in use with several federal agencies. If the data validates, we then pass it to Directus , an open source headless CMS; this saved us developing an API for our Postgres instance, as it can automatically inspect a table and present an HTTPS POST API for CRUD operations on those tables. The entire stack is managed as a CloudFoundry buildpack running on cloud.gov . Everything used in the pilot is free and open source software. This site documents each of these pieces: how to maintain, build, test, and deploy the components involved.","title":"Overview"},{"location":"hardware/pi/","text":"Raspberry Pi For the pilot, we settled on the Raspberry Pi as an implementation platform. It is low-cost open hardware, and is readily available both from brick-and-mortar retailers as well as many web outlets. For the pilot, we used the Model 4b .This makes it a quad-core, 1.5GHz ARM-based Debian device with 4GB of RAM. We have also tested on a 3B+ with 1GB of RAM. It is our belief that a low-spec model (3B or 4B with 1GB or 2GB of RAM) and a 16GB microSD card or larger will more-than-adequately work as a platform for this pilot. For the Future It is possible for an old Intel-based laptop or computer to serve as the host for this project. We believe the number of changes required (to adapt to the new operating system) far outweigh the low cost and ready availability of the Raspberry Pi.","title":"Pi"},{"location":"hardware/pi/#raspberry-pi","text":"For the pilot, we settled on the Raspberry Pi as an implementation platform. It is low-cost open hardware, and is readily available both from brick-and-mortar retailers as well as many web outlets. For the pilot, we used the Model 4b .This makes it a quad-core, 1.5GHz ARM-based Debian device with 4GB of RAM. We have also tested on a 3B+ with 1GB of RAM. It is our belief that a low-spec model (3B or 4B with 1GB or 2GB of RAM) and a 16GB microSD card or larger will more-than-adequately work as a platform for this pilot.","title":"Raspberry Pi"},{"location":"hardware/pi/#for-the-future","text":"It is possible for an old Intel-based laptop or computer to serve as the host for this project. We believe the number of changes required (to adapt to the new operating system) far outweigh the low cost and ready availability of the Raspberry Pi.","title":"For the Future"},{"location":"hardware/wifi/","text":"WiFi The wifi chipset built into the Raspberry Pi is not capable of listening (generally) to ambient wifi due to BIOS limitations. For that reason, we chose to use an external wifi device. The Ralink chipset is widely supported under Linux, and low cost devices can easily be found from many retailiers. We used the PAU06 and PAU09 devices (2.4GHz and 5GHz, respectively) for testing in the pilot. For the future We developed a small application ( find-ralink ) that searches out and provides configuration about these devices when they are plugged into the RPi. It is a \"hardware search tool\" of sorts, and can be extended to support/find additional chipsets and hardware in the future. As additional devices are confirmed to work, the search list can be extended, and the utility of the tool improved.","title":"Wifi Adapters"},{"location":"hardware/wifi/#wifi","text":"The wifi chipset built into the Raspberry Pi is not capable of listening (generally) to ambient wifi due to BIOS limitations. For that reason, we chose to use an external wifi device. The Ralink chipset is widely supported under Linux, and low cost devices can easily be found from many retailiers. We used the PAU06 and PAU09 devices (2.4GHz and 5GHz, respectively) for testing in the pilot.","title":"WiFi"},{"location":"hardware/wifi/#for-the-future","text":"We developed a small application ( find-ralink ) that searches out and provides configuration about these devices when they are plugged into the RPi. It is a \"hardware search tool\" of sorts, and can be extended to support/find additional chipsets and hardware in the future. As additional devices are confirmed to work, the search list can be extended, and the utility of the tool improved.","title":"For the future"},{"location":"setup/bootstrap/","text":"Bootstrap To set up a Raspberry Pi, a librarian first needs to install the Raspbian OS onto a microSD card, and then they need to run our bootstrap script. Installing the OS To setup the Raspberry Pi, we first ask the user to download the Raspberry Pi Imager . This is a free and open tool for Mac, Windows, and Linux that aids in the creation of microSD cards for the Pi. The imaging tool allows the user to select their operating system (there are multiple options), and then install it on a microSD card plugged into their computer. It is free, open, reliable, and makes it very easy to set up the \"boot disk\" for the Raspberry Pi. Running the bootstrap The bootstrap is a bash script that does three things: The bootstrap runs input-initial-configuration . This is a go program 18F developed to: Read in the api.data.gov access token. Read in the FCFS Seq Id for the library where the Pi is deployed. Read in a hardware identification tag that helps the librarian know where the device is installed (eg. \"reference desk\"). The bootstrap makes sure git is installed. It installs the most recent version of ansible from the official Ansible PPA. It pulls the imls-client-pi-playbook repository and runs the ansible playbook contained therein. The librarian runs the bootstrap by opening a terminal and pasting in a command that looks like bash <(curl -s ...) , where the URL is to a file in a Github repository. This downloads the script and executes it. Not only is the bootstrap never used again, it is not possible to use the bootstrap a second time, as we will explain while discussing the playbook . About the bootstrap We considered multiple paths to bootstrapping a Raspberry Pi. There are custom IoT operating systems that can be used or licensed. For a pilot, this was not a path we wanted to explore. These often have specific packaging and signing requirements, and further, we were not confident that a librarian (working unsupported) could actually configure a device running one of these operating systems. We considered building a custom Raspbian image that \"baked in\" the setup scripts. However, there was always the problem of getting an api.data.gov key onto the device. Either a librarian had to boot the Pi and enter the key, or some kind of tricky \"name your keyfile this and save it on a USB stick called this \" would have been necessary. This is what led us to our final approach, which was... Use the stock operating system image. This is the image that has the highest probability of being up-to-date, most secure, and most easily used as a \"fixed point\" in our configuration. It has the best support for installation (the imager \"just works\"), and the bootstrap script becomes a single-line copy-paste instruction to the librarian. If we were scaling, we could consider other approaches, but the questions would be come: Is another approach easier for the user? Is another approach less error prone for the user? Is another approach more secure for the user? and each of these questions (and others) would have to be held in balance with each-other. We believe our bootstrap solution is simple, reasonably secure, and able to be carried out by a wide range of users.","title":"Bootstrap"},{"location":"setup/bootstrap/#bootstrap","text":"To set up a Raspberry Pi, a librarian first needs to install the Raspbian OS onto a microSD card, and then they need to run our bootstrap script.","title":"Bootstrap"},{"location":"setup/bootstrap/#installing-the-os","text":"To setup the Raspberry Pi, we first ask the user to download the Raspberry Pi Imager . This is a free and open tool for Mac, Windows, and Linux that aids in the creation of microSD cards for the Pi. The imaging tool allows the user to select their operating system (there are multiple options), and then install it on a microSD card plugged into their computer. It is free, open, reliable, and makes it very easy to set up the \"boot disk\" for the Raspberry Pi.","title":"Installing the OS"},{"location":"setup/bootstrap/#running-the-bootstrap","text":"The bootstrap is a bash script that does three things: The bootstrap runs input-initial-configuration . This is a go program 18F developed to: Read in the api.data.gov access token. Read in the FCFS Seq Id for the library where the Pi is deployed. Read in a hardware identification tag that helps the librarian know where the device is installed (eg. \"reference desk\"). The bootstrap makes sure git is installed. It installs the most recent version of ansible from the official Ansible PPA. It pulls the imls-client-pi-playbook repository and runs the ansible playbook contained therein. The librarian runs the bootstrap by opening a terminal and pasting in a command that looks like bash <(curl -s ...) , where the URL is to a file in a Github repository. This downloads the script and executes it. Not only is the bootstrap never used again, it is not possible to use the bootstrap a second time, as we will explain while discussing the playbook .","title":"Running the bootstrap"},{"location":"setup/bootstrap/#about-the-bootstrap","text":"We considered multiple paths to bootstrapping a Raspberry Pi. There are custom IoT operating systems that can be used or licensed. For a pilot, this was not a path we wanted to explore. These often have specific packaging and signing requirements, and further, we were not confident that a librarian (working unsupported) could actually configure a device running one of these operating systems. We considered building a custom Raspbian image that \"baked in\" the setup scripts. However, there was always the problem of getting an api.data.gov key onto the device. Either a librarian had to boot the Pi and enter the key, or some kind of tricky \"name your keyfile this and save it on a USB stick called this \" would have been necessary. This is what led us to our final approach, which was... Use the stock operating system image. This is the image that has the highest probability of being up-to-date, most secure, and most easily used as a \"fixed point\" in our configuration. It has the best support for installation (the imager \"just works\"), and the bootstrap script becomes a single-line copy-paste instruction to the librarian. If we were scaling, we could consider other approaches, but the questions would be come: Is another approach easier for the user? Is another approach less error prone for the user? Is another approach more secure for the user? and each of these questions (and others) would have to be held in balance with each-other. We believe our bootstrap solution is simple, reasonably secure, and able to be carried out by a wide range of users.","title":"About the bootstrap"},{"location":"setup/playbook/","text":"Ansible Playbook We attempted to bootstrap the device using as little bash as possible. While ubiquitous as a shell/programming language, it is fragile and error prone. Therefore, we do as little in bash as possible, and immediately bootstrap to ansible , a widely used open source server automation framework supported by Red Hat. Roles Ansible arranges automation into \"playbooks,\" which are YAML documents describing actions to be taken on a server. We have one playbook arranged into multiple \"roles.\" Each role is responsible for a different aspect of the Raspberry Pi configuration. input-initial-configuration : Installs and runs our tool for gathering the FCFS Seq Id and API token from the librarian. packages : We begin with a role that takes responsibility for installing, updating, and removing packages from the Pi. For example, we install lshw , a tool for reporting on the hardware connected to the Pi, but remove packages like apache and nginx , because we do not want any externally visible services running on the device. unattended-upgrades : This role makes sure that unattended upgrades are enabled on the Raspberry Pi. This way, the device automatically gets critical service updates from the Debian package repositories. session-counter : Configures and installs the software for monitoring wifi usage. configure-monitor-mode : Configures the Raspberry Pi hardware for sensing and data collection. lockdown : This package makes a few changes. One, it brings up a firewall that prohibits all external connections to the Raspberry Pi. Two, it disables login for all accounts. At this point, it becomes impossible to log into the Pi ever again. In short, configuring a Raspberry Pi for use with our tools is a one-way trip, and not even the librarian can access the device after configuration. devsec.hardening.os_hardening : Uses an externally provided playbook that is intended to be compliant with the Inspec DevSec Baselines. This particular playbook is written against the Linux baseline. devsec.hardening.ssh_hardening : Uses an externally provided playbook that is intended to be compliant with the Inspec DevSec Baselines. This particular playbook is written against the SSH baseline. Between 6, 7, and 8, the Raspberry Pi is now: Inaccessible : there are no open ports, and even if the device is plugged in, no accounts can log in interactively. Hardened : we have run playbooks that intend to be compliant against baselines in order to limit access to the Pi. Maintenance When the playbook is done, the Pi is ready for use. This same playbook is then run periodically (daily), and in this way, we can later update the devices in production. We might add packages, change configuration, and so on... but we can do so knowing that no one has modified the device without our knowledge. To modify the playbook, someone would need commit access to a Github repository. Therefore, managing who has access to the playbook is critical to managing the security of the Raspberry Pis in production. We think this is reasonable. Caveats We believe we have brought a healthy level of paranoia to our development process. As configured by the playbook, are very close to completely meeting the Iot Device Cybersecurity Capability Core Baseline (NISTIR 8259A). However, we want to highlight two caveats: Ownership . If this were to scale, it is important to remember that the Pis being used are not owned or controlled by the federal government. They will be devices purchased and set up by libraries, and whether or not NIST or other controls apply is potentially a subject for debate. Our intent is that they use the tools we've developed, as a result we believe that the resulting \"hardened\" Pi is no longer an easily hacked device that might become part of an attack surface/vector within a library. Theft . If someone steals a Pi from the library, all bets are off . Someone could remove the microSD card from the Pi and read it/modify it/etc. At that point, our access controls do not matter. Further, because of how the Pi is designed, we cannot encrypt the filesystem of the Raspberry Pi . This is just one of many reasons that we do not store any data on the local filesystem. There are ways we could encrypt the Pis. Most of those solutions will require a librarian to physically interact with the device in case of a power outage, the device being unplugged, and so on. At that point, the utility of the Raspberry Pi as an \"automatic\" and \"autonomous\" sensor is greatly reduced. We believe we have made appropriate trade-offs in terms of security and utility in our design, and are not putting libraries or our communities at risk through our design.","title":"Playbook"},{"location":"setup/playbook/#ansible-playbook","text":"We attempted to bootstrap the device using as little bash as possible. While ubiquitous as a shell/programming language, it is fragile and error prone. Therefore, we do as little in bash as possible, and immediately bootstrap to ansible , a widely used open source server automation framework supported by Red Hat.","title":"Ansible Playbook"},{"location":"setup/playbook/#roles","text":"Ansible arranges automation into \"playbooks,\" which are YAML documents describing actions to be taken on a server. We have one playbook arranged into multiple \"roles.\" Each role is responsible for a different aspect of the Raspberry Pi configuration. input-initial-configuration : Installs and runs our tool for gathering the FCFS Seq Id and API token from the librarian. packages : We begin with a role that takes responsibility for installing, updating, and removing packages from the Pi. For example, we install lshw , a tool for reporting on the hardware connected to the Pi, but remove packages like apache and nginx , because we do not want any externally visible services running on the device. unattended-upgrades : This role makes sure that unattended upgrades are enabled on the Raspberry Pi. This way, the device automatically gets critical service updates from the Debian package repositories. session-counter : Configures and installs the software for monitoring wifi usage. configure-monitor-mode : Configures the Raspberry Pi hardware for sensing and data collection. lockdown : This package makes a few changes. One, it brings up a firewall that prohibits all external connections to the Raspberry Pi. Two, it disables login for all accounts. At this point, it becomes impossible to log into the Pi ever again. In short, configuring a Raspberry Pi for use with our tools is a one-way trip, and not even the librarian can access the device after configuration. devsec.hardening.os_hardening : Uses an externally provided playbook that is intended to be compliant with the Inspec DevSec Baselines. This particular playbook is written against the Linux baseline. devsec.hardening.ssh_hardening : Uses an externally provided playbook that is intended to be compliant with the Inspec DevSec Baselines. This particular playbook is written against the SSH baseline. Between 6, 7, and 8, the Raspberry Pi is now: Inaccessible : there are no open ports, and even if the device is plugged in, no accounts can log in interactively. Hardened : we have run playbooks that intend to be compliant against baselines in order to limit access to the Pi.","title":"Roles"},{"location":"setup/playbook/#maintenance","text":"When the playbook is done, the Pi is ready for use. This same playbook is then run periodically (daily), and in this way, we can later update the devices in production. We might add packages, change configuration, and so on... but we can do so knowing that no one has modified the device without our knowledge. To modify the playbook, someone would need commit access to a Github repository. Therefore, managing who has access to the playbook is critical to managing the security of the Raspberry Pis in production. We think this is reasonable.","title":"Maintenance"},{"location":"setup/playbook/#caveats","text":"We believe we have brought a healthy level of paranoia to our development process. As configured by the playbook, are very close to completely meeting the Iot Device Cybersecurity Capability Core Baseline (NISTIR 8259A). However, we want to highlight two caveats: Ownership . If this were to scale, it is important to remember that the Pis being used are not owned or controlled by the federal government. They will be devices purchased and set up by libraries, and whether or not NIST or other controls apply is potentially a subject for debate. Our intent is that they use the tools we've developed, as a result we believe that the resulting \"hardened\" Pi is no longer an easily hacked device that might become part of an attack surface/vector within a library. Theft . If someone steals a Pi from the library, all bets are off . Someone could remove the microSD card from the Pi and read it/modify it/etc. At that point, our access controls do not matter. Further, because of how the Pi is designed, we cannot encrypt the filesystem of the Raspberry Pi . This is just one of many reasons that we do not store any data on the local filesystem. There are ways we could encrypt the Pis. Most of those solutions will require a librarian to physically interact with the device in case of a power outage, the device being unplugged, and so on. At that point, the utility of the Raspberry Pi as an \"automatic\" and \"autonomous\" sensor is greatly reduced. We believe we have made appropriate trade-offs in terms of security and utility in our design, and are not putting libraries or our communities at risk through our design.","title":"Caveats"},{"location":"software/find-ralink/","text":"","title":"Find Wifi Hardware"},{"location":"software/input-initial-configuration/","text":"","title":"Initial Configuration"},{"location":"software/session-counter/","text":"","title":"Session Counter"},{"location":"stack/apidatagov/","text":"Overview api.data.gov provides free API management services for federal agencies. (The underlying framework is API Umbrella ). We use this service primarily for managing users and API keys. Using an API layer in this way allows us to provide transparent and seamless (to the user) backend updates. As a secondary benefit, we also get rate limiting and usage statistics. Please note that all API calls to api.data.gov must have a X-Api-Key request header with a valid API key for the path in question. Otherwise, the user will get an API_KEY_INVALID response. Configuration We have set up a predefined path at /TEST/10x-imls/ . To route the API call properly, we want to specify the Rabbit and Directus hosts to use. Since everything goes through Rabbit first (for validation purposes), we have configured Rabbit to read Directus configuration data via request headers. Our application sends a request to api.data.gov/TEST/10x-imls/v1/ with the appropriate X-Api-Key header and key api.data.gov looks up /TEST/10x-imls/ , and routes the request to our configuration api.data.gov looks up /v1/ in our API backend list The backend host is identified as 10x-rabbit-demo.app.cloud.gov Our \"Global Request Settings\" configuration tells api.data.gov to add these Rabbit-specific headers: X-Magic-Header X-Directus-Host X-Directus-Token X-Directus-Schema-Version Finally, the modified request is proxied (passed on) to the backend host with the path /validate/ Thus, a request to https://api.data.gov/TEST/10x-imls/v1/ is routed to https://10x-rabbit-demo.app.cloud.gov/validate/ with additional headers. Updates Currently we only offer the /v1/ path, but further revisions to our server stack are quite likely. Should we add /v2/ in the future, we will push an ansible update that configures our application to hit /v2/ instead. Because the backend beyond api.data.gov is essentially invisible to the user, the new endpoint could use entirely new backend services if needed.","title":"api.data.gov"},{"location":"stack/apidatagov/#overview","text":"api.data.gov provides free API management services for federal agencies. (The underlying framework is API Umbrella ). We use this service primarily for managing users and API keys. Using an API layer in this way allows us to provide transparent and seamless (to the user) backend updates. As a secondary benefit, we also get rate limiting and usage statistics. Please note that all API calls to api.data.gov must have a X-Api-Key request header with a valid API key for the path in question. Otherwise, the user will get an API_KEY_INVALID response.","title":"Overview"},{"location":"stack/apidatagov/#configuration","text":"We have set up a predefined path at /TEST/10x-imls/ . To route the API call properly, we want to specify the Rabbit and Directus hosts to use. Since everything goes through Rabbit first (for validation purposes), we have configured Rabbit to read Directus configuration data via request headers. Our application sends a request to api.data.gov/TEST/10x-imls/v1/ with the appropriate X-Api-Key header and key api.data.gov looks up /TEST/10x-imls/ , and routes the request to our configuration api.data.gov looks up /v1/ in our API backend list The backend host is identified as 10x-rabbit-demo.app.cloud.gov Our \"Global Request Settings\" configuration tells api.data.gov to add these Rabbit-specific headers: X-Magic-Header X-Directus-Host X-Directus-Token X-Directus-Schema-Version Finally, the modified request is proxied (passed on) to the backend host with the path /validate/ Thus, a request to https://api.data.gov/TEST/10x-imls/v1/ is routed to https://10x-rabbit-demo.app.cloud.gov/validate/ with additional headers.","title":"Configuration"},{"location":"stack/apidatagov/#updates","text":"Currently we only offer the /v1/ path, but further revisions to our server stack are quite likely. Should we add /v2/ in the future, we will push an ansible update that configures our application to hit /v2/ instead. Because the backend beyond api.data.gov is essentially invisible to the user, the new endpoint could use entirely new backend services if needed.","title":"Updates"},{"location":"stack/directus/","text":"","title":"Directus"},{"location":"stack/reval/","text":"ReVal ReVal (Reusable Validation Library) is a Django application for validating data via an API and web interface. ReVal was originally developed for the USDA FNS (Food and Nutrition Service) Data Validation Service in order to validate National School Lunch and Breakfast data . We have configured our ReVal instance, called Rabbit , to be a stateless validation application deployed on cloud.gov at 10x-rabbit-demo.app.cloud.gov . Configuration Rabbit provides one endpoint: /validate/<collection>/ . The only action allowed is POST . This endpoint takes an arbitrary array of JSON data, grabs the corresponding validation schema for that collection from the Directus host given, validates data against the schema, and returns the result of validation, successful or otherwise. Rabbit requires three HTTP headers: X-Magic-Header : secret key for the rabbit instance X-Directus-Host : Directus host (currently 10x-rabbit-data.app.cloud.gov ) X-Directus-Token : Directus token Errors from the Directus instance (if any) will be returned verbatim. Otherwise, the endpoint returns a standard ReVal validation object in JSON . Usage We proxy all api.data.gov requests through Rabbit for validation purposes: the data must be a JSON array of predefined objects. We use the following validation schemas: events and wifi . All Rabbit requests are also logged to a separate, generic Directus table. Should the data not pass validation, the resulting validation errors are also stored in a separate table. The current v1 schema is defined here . To avoid abuse of any Rabbit endpoint, we mandate a secret key to be passed in via the X-Magic-Header . This header is set on the api.data.gov backend configuration.","title":"ReVal (Rabbit)"},{"location":"stack/reval/#reval","text":"ReVal (Reusable Validation Library) is a Django application for validating data via an API and web interface. ReVal was originally developed for the USDA FNS (Food and Nutrition Service) Data Validation Service in order to validate National School Lunch and Breakfast data . We have configured our ReVal instance, called Rabbit , to be a stateless validation application deployed on cloud.gov at 10x-rabbit-demo.app.cloud.gov .","title":"ReVal"},{"location":"stack/reval/#configuration","text":"Rabbit provides one endpoint: /validate/<collection>/ . The only action allowed is POST . This endpoint takes an arbitrary array of JSON data, grabs the corresponding validation schema for that collection from the Directus host given, validates data against the schema, and returns the result of validation, successful or otherwise. Rabbit requires three HTTP headers: X-Magic-Header : secret key for the rabbit instance X-Directus-Host : Directus host (currently 10x-rabbit-data.app.cloud.gov ) X-Directus-Token : Directus token Errors from the Directus instance (if any) will be returned verbatim. Otherwise, the endpoint returns a standard ReVal validation object in JSON .","title":"Configuration"},{"location":"stack/reval/#usage","text":"We proxy all api.data.gov requests through Rabbit for validation purposes: the data must be a JSON array of predefined objects. We use the following validation schemas: events and wifi . All Rabbit requests are also logged to a separate, generic Directus table. Should the data not pass validation, the resulting validation errors are also stored in a separate table. The current v1 schema is defined here . To avoid abuse of any Rabbit endpoint, we mandate a secret key to be passed in via the X-Magic-Header . This header is set on the api.data.gov backend configuration.","title":"Usage"}]}